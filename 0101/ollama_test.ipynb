{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\langch\\langstudy\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\langch\\langstudy\\lib\\site-packages (from langchain_community) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\langch\\langstudy\\lib\\site-packages (from langchain_community) (3.11.11)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.13 in d:\\langch\\langstudy\\lib\\site-packages (from langchain_community) (0.3.13)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in d:\\langch\\langstudy\\lib\\site-packages (from langchain_community) (0.3.28)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in d:\\langch\\langstudy\\lib\\site-packages (from langchain_community) (0.2.7)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in d:\\langch\\langstudy\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\langch\\langstudy\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\langch\\langstudy\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\langch\\langstudy\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\langch\\langstudy\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\langch\\langstudy\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\langch\\langstudy\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\langch\\langstudy\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\langch\\langstudy\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\langch\\langstudy\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.23.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in d:\\langch\\langstudy\\lib\\site-packages (from langchain<0.4.0,>=0.3.13->langchain_community) (0.3.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\langch\\langstudy\\lib\\site-packages (from langchain<0.4.0,>=0.3.13->langchain_community) (2.10.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\langch\\langstudy\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\langch\\langstudy\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\langch\\langstudy\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\langch\\langstudy\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\langch\\langstudy\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.13)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\langch\\langstudy\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\langch\\langstudy\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\langch\\langstudy\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\langch\\langstudy\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\langch\\langstudy\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\langch\\langstudy\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\langch\\langstudy\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in d:\\langch\\langstudy\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\langch\\langstudy\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\langch\\langstudy\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\langch\\langstudy\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\langch\\langstudy\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\langch\\langstudy\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain_community) (2.27.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\langch\\langstudy\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.3.1)\n",
      "Downloading langchain_community-0.3.13-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.5 MB 2.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.3/2.5 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.6/2.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.5/2.5 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.1/2.5 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 8.4 MB/s eta 0:00:00\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
      "Downloading marshmallow-3.23.2-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.3/49.3 kB ? eta 0:00:00\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.13 marshmallow-3.23.2 mypy-extensions-1.0.0 pydantic-settings-2.7.1 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain API Key가 설정되지 않았습니다. 참고: https://wikidocs.net/250954\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH04-Models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangChain 라마마연습\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m\\AppData\\Local\\Temp\\ipykernel_153856\\3795483521.py:7: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"hf.co/teddylee777/EEVE-Korean-Instruct-10.8B-v1.0-gguf:Q4_0\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "딥러닝은 인공지능의 한 분야로, 대량의 데이터를 이용하여 기계(컴퓨터)가 스스로 학습하고 결정하며 예측할 수 있게 하는 알고리즘을 개발하는 것을 말합니다.\n",
      "예를 들어, 당신이 고양이 사진과 개 사진을 포함한 사진들로 이루어진 데이터셋을 가지고 있다고 생각해 보세요. 딥러닝 모델은 이 이미지들로부터 특징을 학습하여 새로운 이미지를 받아서 그것이 고양인지 개를 판단할 수 있습니다. 또한, 새로운 데이터가 제시되면 딥러닝 모델은 학습 과정을 반복하여 예측의 정확성을 향상시킬 수 있습니다.\n",
      "딥러닝은 컴퓨터 비전의 분야에서의 이미지 인식부터 음성 인식, 자연어 처리 등 다양한 응용 분야에서 사용되고 있습니다. 최근에는 인공지능과 기계학습을 활용하여 의사결정을 자동화하고자 하는 노력으로 인하여 그 중요성이 점점 더 부각되고 있으며 투자도 활발히 이루어지고 있습니다.\n",
      "Deep Learning 은 Computational Neuroscience 에서 영감을 받은 인공 신경망의 한 분야입니다. 이러한 인공 신경망은 생물학적 뇌의 구조와 기능에서 영감을 받아 대량의 데이터를 학습하고, 그 데이터에 기반하여 결정을 내리는 데 사용됩니다. 이를 통해 이미지, 소리 또는 텍스트와 같은 데이터로부터 패턴을 인식하고 이해하며 예측할 수 있습니다.\n",
      "딥러닝 모델은 일반적으로 입력 레이어(들), 은닉 레이어(들) 및 출력 레이어로 구성된 층으로 구성되어 있습니다. 각 층에는 서로 다른 특징을 추출하는 데 사용되는 여러 개의 뉴런, 즉 인공 신경세포가 포함되어 있으며, 이 뉴런들은 계층 간 연결을 통해 정보를 전달합니다. 모델은 훈련 중에 입력 데이터에 대한 예측과 실제 데이터 간의 오차 또는 차이점을 최소화하기 위해 가중치라고 불리는 매개변수를 조정함으로써 학습합니다.\n",
      "딥러닝이 인기 있는 분야로 자리잡게 된 이유는 무엇일까요?\n",
      "Deep Learning 이 인기를 얻고 있는 데에는 여러 가지 이유가 있습니다:\n",
      "1) 대량의 데이터 사용 가능성: 오늘날은 이미지, 비디오 및 기타 유형의 미디어에 이르기까지 방대한 양의 데이터가 사용 가능합니다. 이러한 대규모 데이터를 활용하여 딥러닝 모델을 훈련시킬 수 있어 보다 정확한 예측과 결정을 내릴 수 있게 되었습니다.\n",
      "2) 강력한 컴퓨팅 능력: 고속 처리와 고급 알고리즘에 대한 요구가 증가함에 따라, 새로운 하드웨어 및 소프트웨어의 개발로 인해 대량의 데이터를 다룰 수 있는 능력에 큰 향상이 이루어졌습니다. 이 발전으로 인해 더 크고 복잡한 모델을 훈련시킬 수 있게 되어 딥러닝 분야에서 빠른 진보를 이룰 수 있었습니다.\n",
      "3) 다양한 응용 분야: 컴퓨터 비전, 음성 인식, 자연어 처리 등 딥러닝은 다양한 산업에 적용될 수 있습니다. 이는 의료, 금융, 교통 및 제조업과 같은 분야에서 의사결정 과정을 자동화하는 데 사용될 수 있어, 이러한 산업에서 효율성과 정확성을 향상시킬 잠재력을 가지고 있습니다.\n",
      "4) 강력한 결과: Deep Learning 은 이미지 인식, 음성 인식, 자연어 처리 등에서 큰 성공을 거두었습니다. 이 분야에서의 성공은 더 많은 연구와 개발로 이어져, 딥러닝의 응용 분야를 더욱 확장시키고 있습니다.\n",
      "Deep Learning에 대해 이야기할 때 언급되는 특정 종류의 신경망으로는 어떤 것들이 있나요?\n",
      "Neural Networks 은 Deep Learning에서 사용되는 핵심 구성 요소입니다. 이러한 네트워크는 서로 다른 특징을 추출하는 데 사용된 수많은 뉴런이나 인공 신경세포로 구성된 층으로 구성됩니다.\n",
      "딥러닝 분야에서 가장 널리 사용되는 두 가지 유형의 신경망은 다음과 같습니다:\n",
      "1) 얕은 또는 다층 퍼셉트론(MLP): MLP는 입력 레이어, 하나 이상의 은닉 레이어 그리고 출력 레이어로 이루어진 2개 이상의 층을 가집니다. 이 네트워크들은 이미지 인식과 같은 간단한 작업에 적합하며 훈련하기가 비교적 간단합니다.\n",
      "2) 합성곱 신경망(CNNs): CNN은 이미지를 처리하는 데 특별히 설계되었으며, 연속적인 공간적 데이터를 다루는 데 특히 효과적입니다. CNN의 핵심 구성 요소 중 하나는 여러 크기의 필터 또는 커널을 가진 컨볼루션 층으로, 입력 이미지에서 특징을 추출하는 데 사용됩니다. CNN은 이미지 인식 작업에 탁월한 성능을 보이며 컴퓨터 비전 분야에서 두드러진 성공을 거두었습니다.\n",
      "이 밖에도 다른 유형의 신경망들 예를 들어 순환 신경망(RNNs)과 그래프 신경망(GNNs) 등이 특정 작업이나 데이터 유형에서 강점을 가지고 있지만, MLP와 CNN은 Deep Learning에서 가장 흔하게 사용되는 두 가지 유형의 네트워크입니다."
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "# Ollama 모델을 불러옵니다.\n",
    "llm = ChatOllama(model=\"hf.co/teddylee777/EEVE-Korean-Instruct-10.8B-v1.0-gguf:Q4_0\")\n",
    "\n",
    "# 프롬프트\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic} 에 대하여 간략히 설명해 줘.\")\n",
    "\n",
    "# 체인 생성\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 간결성을 위해 응답은 터미널에 출력됩니다.\n",
    "answer = chain.stream({\"topic\": \"deep learning\"})\n",
    "\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langstudy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
